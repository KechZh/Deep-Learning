{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import os\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from keras import Sequential, Input\n",
    "from keras.layers import Dense, BatchNormalization, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"5\"\n",
    "gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.2)\n",
    "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/air_visit_data.csv'\n",
    "vis = pd.read_csv(path)\n",
    "path = 'data/air_reserve.csv'\n",
    "ares = pd.read_csv(path)\n",
    "path = 'data/hpg_reserve.csv'\n",
    "hres = pd.read_csv(path)\n",
    "path = 'data/air_store_info.csv'\n",
    "astore = pd.read_csv(path)\n",
    "path = 'data/hpg_store_info.csv'\n",
    "hstore = pd.read_csv(path)\n",
    "path = 'data/store_id_relation.csv'\n",
    "sid = pd.read_csv(path)\n",
    "path = 'data/date_info.csv'\n",
    "hol = pd.read_csv(path).rename(columns={'calendar_date':'visit_date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:6692: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  sort=sort)\n"
     ]
    }
   ],
   "source": [
    "hres = pd.merge(hres, sid, how='inner', on=['hpg_store_id'])\n",
    "hres.drop('hpg_store_id', axis=1, inplace=True)\n",
    "ares = ares.append(hres)\n",
    "\n",
    "ares['visit_datetime'] = pd.to_datetime(ares['visit_datetime'])\n",
    "ares['visit_date'] = ares['visit_datetime'].dt.date\n",
    "ares.drop('visit_datetime', axis=1, inplace=True)\n",
    "ares.drop('reserve_datetime', axis=1, inplace=True)\n",
    "\n",
    "ares = ares.groupby(['air_store_id','visit_date'], as_index=False).sum().reset_index()\n",
    "ares = ares.drop(['index'], axis=1)\n",
    "\n",
    "vis['visit_datetime'] = pd.to_datetime(vis['visit_date'])\n",
    "vis['visit_date'] = vis['visit_datetime'].dt.date\n",
    "\n",
    "hol['visit_date'] = pd.to_datetime(hol['visit_date'])\n",
    "hol['visit_date'] = hol['visit_date'].dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(vis, ares, how='left', on=['air_store_id', 'visit_date'])\n",
    "df = pd.merge(df, astore, how='inner', on='air_store_id')\n",
    "df = pd.merge(df, hol, how='left', on='visit_date')\n",
    "\n",
    "df['year'] = df['visit_datetime'].dt.year\n",
    "df['month'] = df['visit_datetime'].dt.month\n",
    "df['day'] = df['visit_datetime'].dt.day\n",
    "df.drop('visit_datetime', axis=1, inplace=True)\n",
    "\n",
    "features = [col for col in ['air_genre_name', 'air_area_name', 'day_of_week']]\n",
    "for col in features:\n",
    "    tmp = pd.get_dummies(pd.Series(df[col]))\n",
    "    df = pd.concat([df, tmp], axis=1)\n",
    "    df.drop([col], axis=1, inplace=True)\n",
    "\n",
    "df.fillna(0, inplace=True)\n",
    "\n",
    "df['visitors'] = np.log1p(df['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/pandas/core/frame.py:3940: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "train = df[(df['year'] == 2016)]\n",
    "train.drop('air_store_id', axis=1, inplace=True)\n",
    "train.drop('visit_date', axis=1, inplace=True)\n",
    "test = df[(df['year'] == 2017)]\n",
    "test.drop('air_store_id', axis=1, inplace=True)\n",
    "test.drop('visit_date', axis=1, inplace=True)\n",
    "\n",
    "train_X = train.drop('visitors', axis=1)\n",
    "train_Y = (train['visitors'])\n",
    "test_X = test.drop('visitors', axis=1)\n",
    "test_Y = (test['visitors'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(100, activation = 'relu', input_shape = (train_X.shape[1],)))\n",
    "model.add(Dense(50, activation = 'relu'))\n",
    "model.add(Dense(20, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss = 'mse', optimizer = Adam(lr = 0.001, decay = 0.0001), metrics = ['mean_squared_logarithmic_error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "174535/174535 [==============================] - 11s 61us/step - loss: 7.5808 - mean_squared_logarithmic_error: 0.1141\n",
      "Epoch 2/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.7916 - mean_squared_logarithmic_error: 0.0665\n",
      "Epoch 3/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 1.0430 - mean_squared_logarithmic_error: 0.0869\n",
      "Epoch 4/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.9530 - mean_squared_logarithmic_error: 0.0786\n",
      "Epoch 5/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.8530 - mean_squared_logarithmic_error: 0.0714\n",
      "Epoch 6/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.7683 - mean_squared_logarithmic_error: 0.0643\n",
      "Epoch 7/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.7492 - mean_squared_logarithmic_error: 0.0629\n",
      "Epoch 8/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.6721 - mean_squared_logarithmic_error: 0.0573\n",
      "Epoch 9/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.6679 - mean_squared_logarithmic_error: 0.0570\n",
      "Epoch 10/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.6459 - mean_squared_logarithmic_error: 0.0555\n",
      "Epoch 11/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.6512 - mean_squared_logarithmic_error: 0.0558\n",
      "Epoch 12/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.6149 - mean_squared_logarithmic_error: 0.0532\n",
      "Epoch 13/50\n",
      "174535/174535 [==============================] - 9s 54us/step - loss: 0.6252 - mean_squared_logarithmic_error: 0.0539\n",
      "Epoch 14/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5961 - mean_squared_logarithmic_error: 0.0520\n",
      "Epoch 15/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5989 - mean_squared_logarithmic_error: 0.0521\n",
      "Epoch 16/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.5921 - mean_squared_logarithmic_error: 0.0516\n",
      "Epoch 17/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5898 - mean_squared_logarithmic_error: 0.0515\n",
      "Epoch 18/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5781 - mean_squared_logarithmic_error: 0.0507\n",
      "Epoch 19/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5763 - mean_squared_logarithmic_error: 0.0505\n",
      "Epoch 20/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5806 - mean_squared_logarithmic_error: 0.0508\n",
      "Epoch 21/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5724 - mean_squared_logarithmic_error: 0.0503\n",
      "Epoch 22/50\n",
      "174535/174535 [==============================] - 9s 54us/step - loss: 0.5696 - mean_squared_logarithmic_error: 0.0500\n",
      "Epoch 23/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.5658 - mean_squared_logarithmic_error: 0.0498\n",
      "Epoch 24/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5632 - mean_squared_logarithmic_error: 0.0496\n",
      "Epoch 25/50\n",
      "174535/174535 [==============================] - 9s 54us/step - loss: 0.5607 - mean_squared_logarithmic_error: 0.0494\n",
      "Epoch 26/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5620 - mean_squared_logarithmic_error: 0.0495\n",
      "Epoch 27/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5636 - mean_squared_logarithmic_error: 0.0497\n",
      "Epoch 28/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5632 - mean_squared_logarithmic_error: 0.0497\n",
      "Epoch 29/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5559 - mean_squared_logarithmic_error: 0.0491\n",
      "Epoch 30/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5533 - mean_squared_logarithmic_error: 0.0489\n",
      "Epoch 31/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5571 - mean_squared_logarithmic_error: 0.0492\n",
      "Epoch 32/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5533 - mean_squared_logarithmic_error: 0.0489\n",
      "Epoch 33/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.5521 - mean_squared_logarithmic_error: 0.0488\n",
      "Epoch 34/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5489 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 35/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.5505 - mean_squared_logarithmic_error: 0.0487\n",
      "Epoch 36/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5487 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 37/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5487 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 38/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5489 - mean_squared_logarithmic_error: 0.0486\n",
      "Epoch 39/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5473 - mean_squared_logarithmic_error: 0.0485\n",
      "Epoch 40/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5458 - mean_squared_logarithmic_error: 0.0484\n",
      "Epoch 41/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5459 - mean_squared_logarithmic_error: 0.0484\n",
      "Epoch 42/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5436 - mean_squared_logarithmic_error: 0.0482\n",
      "Epoch 43/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5458 - mean_squared_logarithmic_error: 0.0484\n",
      "Epoch 44/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5440 - mean_squared_logarithmic_error: 0.0483\n",
      "Epoch 45/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.5441 - mean_squared_logarithmic_error: 0.0483\n",
      "Epoch 46/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5418 - mean_squared_logarithmic_error: 0.0481\n",
      "Epoch 47/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5425 - mean_squared_logarithmic_error: 0.0481\n",
      "Epoch 48/50\n",
      "174535/174535 [==============================] - 9s 52us/step - loss: 0.5412 - mean_squared_logarithmic_error: 0.0480\n",
      "Epoch 49/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5417 - mean_squared_logarithmic_error: 0.0481\n",
      "Epoch 50/50\n",
      "174535/174535 [==============================] - 9s 53us/step - loss: 0.5407 - mean_squared_logarithmic_error: 0.0480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f02dc0e9d30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x = train_X, y = train_Y, epochs = 50, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174535/174535 [==============================] - 9s 53us/step\n",
      "train RMSLE : 0.216836982988462\n",
      "77573/77573 [==============================] - 4s 53us/step\n",
      "test RMSLE : 0.22000846418304632\n"
     ]
    }
   ],
   "source": [
    "pred = model.evaluate(x = train_X, y = train_Y)\n",
    "print('train RMSLE : ' + str(pred[1] ** 0.5))\n",
    "pred = model.evaluate(x = test_X, y = test_Y)\n",
    "print('test RMSLE : ' + str(pred[1] ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
